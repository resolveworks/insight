[package]
name = "insight-core"
version = "0.1.0"
description = "Core business logic for Insight - no Tauri dependency"
edition = "2021"

[dependencies]
# Async runtime
tokio = { version = "1", features = ["full"] }
futures = "0.3"

# iroh P2P
iroh = "0.95"
iroh-blobs = "0.97"
iroh-docs = "0.95"
iroh-gossip = "0.95"
iroh-io = "0.6"

# PDF processing
lopdf = "0.38"

# Search (milli from meilisearch)
milli = { git = "https://github.com/meilisearch/meilisearch.git", tag = "v1.30.1" }
bumpalo = "3"
fst = "0.4.7"
roaring = "0.10.7"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"
chrono = { version = "0.4", features = ["serde"] }
bytes = "1"

# Random
rand = "0.9"

# LLM inference
mistralrs = { git = "https://github.com/EricLBuehler/mistral.rs", branch = "master" }
hf-hub = { version = "0.4", features = ["tokio"] }
tokio-stream = "0.1"
tokio-util = "0.7"

# Remote LLM providers
async-trait = "0.1"
reqwest = { version = "0.12", features = ["json", "stream"] }
async-openai = { version = "0.32", features = ["responses", "model"] }

# Text chunking for embeddings
text-splitter = { version = "0.28", features = ["tokenizers"] }
tokenizers = "0.22"

# Utilities
anyhow = "1"
thiserror = "2"
tracing = "0.1"
dirs = "6"
uuid = { version = "1", features = ["v4"] }

[features]
default = []
# GPU/accelerated builds (optional; CPU-only by default)
cuda = ["mistralrs/cuda", "mistralrs/flash-attn", "mistralrs/cudnn"]
flash-attn = ["mistralrs/flash-attn"]
cudnn = ["mistralrs/cudnn"]
metal = ["mistralrs/metal", "mistralrs/accelerate"]
accelerate = ["mistralrs/accelerate"]
mkl = ["mistralrs/mkl"]

[dev-dependencies]
tempfile = "3"
